{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Mechanism Experiment Template\n",
    "\n",
    "## Experiment #1 \n",
    "\n",
    "(Use a unique identifier for the number next to \"Experiment\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Overview\n",
    "\n",
    "### Key Question\n",
    "\n",
    "In Single-Choice Weighted Plurality, does adding weight for each NFTs produce different results (final winner) than one wallet, one vote?\n",
    "\n",
    "### Procedure for Generating Data\n",
    "\n",
    "A **trial** consists of the following steps:\n",
    "\n",
    "**Step 1:** We load the actual TE Academy data available from the Otterspace subgraph, accessed on May 28. This gives us the real data available to voters. \n",
    "\n",
    "**Step 2:** We create two different weightings for the voters.\n",
    "A. *One Wallet, One Vote:* each voter is assigned a weight of 1.0, regardless of how many NFTs they hold. (This is also *uniform weighting*.)\n",
    "B. *Each NFT has a weight of 1.0*: each voter is assigned a weight equal to the number of NFTs they hold. Each NFT is worth 1.0.\n",
    "\n",
    "**Step 3:** We randomly assign voter choices.\n",
    "\n",
    "**Step 4:** We calculate the results (including final winner) for each weighting, and keep track of results in a DataFrame. \n",
    "\n",
    "We aim to calculate 100_000 trials. \n",
    "\n",
    "### Measurement\n",
    "\n",
    "We measure which proportion of the time the two weightings produced the same winner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import choice\n",
    "from typing import Dict\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  # Add this line to include the directory above\n",
    "\n",
    "# Custom imports\n",
    "from custom_types import UserNFTs\n",
    "from mechanisms.single_choice_weighted_plurality import SingleChoiceWeightedPlurality\n",
    "from mechanisms.group_hug_mechanism import GroupHug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data \n",
    "\n",
    "In the cell below, we are importing the available data as of May 28, 2024 regarding which users have which NFTs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"../data/nft_data_may_28_2024_cleaned.csv\"\n",
    "file_exists = os.path.exists(file_name)\n",
    "file_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input a default voting weights csv (these were suggested by )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_WEIGHTS = pd.read_csv(\"../data/default_voting_weights.csv\")\n",
    "DEFAULT_WEIGHTS.columns = DEFAULT_WEIGHTS.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Category', 'Count', 'Weight'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_WEIGHTS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Count</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TE FUNDAMENTALS COURSE AUTHOR LAUNCH 2022</td>\n",
       "      <td>POE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Token Engineering @EthCC Paris 2023 - Speaker</td>\n",
       "      <td>POE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TE FUNDAMENTALS 1</td>\n",
       "      <td>POK</td>\n",
       "      <td>332.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TE FUNDAMENTALS 2</td>\n",
       "      <td>POK</td>\n",
       "      <td>249.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TE FUNDAMENTALS 3</td>\n",
       "      <td>POK</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name Category  Count  Weight\n",
       "0      TE FUNDAMENTALS COURSE AUTHOR LAUNCH 2022      POE    4.0    20.0\n",
       "1  Token Engineering @EthCC Paris 2023 - Speaker      POE    7.0    16.0\n",
       "2                              TE FUNDAMENTALS 1      POK  332.0     7.0\n",
       "3                              TE FUNDAMENTALS 2      POK  249.0     7.0\n",
       "4                              TE FUNDAMENTALS 3      POK  168.0     7.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_WEIGHTS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\tools\\manim\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\tools\\manim\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -penai-whisper (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -penai-whisper (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -penai-whisper (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -penai-whisper (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -penai-whisper (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -penai-whisper (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_WEIGHTS.at[3, 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # This is intended to replicate the spreadsheet formula =IF(COUNT=0,0,RANDBETWEEN(0,1))\n",
    "\n",
    "    import random\n",
    "\n",
    "    nft_credentials = DEFAULT_WEIGHTS['Name']\n",
    "\n",
    "    def get_nft_count(nft_data: pd.DataFrame, \n",
    "                        row_number: int,\n",
    "                        col_name: str): \n",
    "        return nft_data.at[row_number, col_name]\n",
    "        \n",
    "    def generate_nested_dict(nft_data: pd.DataFrame = DEFAULT_WEIGHTS, \n",
    "                             col_name: str = \"Count\",\n",
    "                             voters=None,\n",
    "                             credentials=None):\n",
    "        nested_dictionary = {}\n",
    "        for voter in voters:\n",
    "            nested_dictionary[voter] = {}\n",
    "            for row_number, credential in enumerate(credentials):\n",
    "                actual_credential_count = get_nft_count(nft_data, \n",
    "                                                        row_number,\n",
    "                                                        col_name)\n",
    "                issued_credential_count = 0  # Start with 0\n",
    "                if actual_credential_count > 0:  # Check if the credential has been issued\n",
    "                    voter_is_issued_credential = random.choice([0, 1])\n",
    "                    nested_dictionary[voter][credential] = voter_is_issued_credential\n",
    "        return nested_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nft_count(nft_data = DEFAULT_WEIGHTS, \n",
    "              row_number = 3,\n",
    "              col_name = 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is voter_3\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "my_name = f\"voter_{x}\"\n",
    "\n",
    "print(f\"My name is {my_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_voter_names = [f\"voter_{(k+1)}\" for k in range(351)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enerate_nested_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m my_voters \u001b[38;5;241m=\u001b[39m \u001b[43menerate_nested_dict\u001b[49m(voters \u001b[38;5;241m=\u001b[39m my_voter_names,\n\u001b[0;32m      2\u001b[0m                      credentials \u001b[38;5;241m=\u001b[39m DEFAULT_WEIGHTS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enerate_nested_dict' is not defined"
     ]
    }
   ],
   "source": [
    "my_voters = enerate_nested_dict(voters = my_voter_names,\n",
    "                     credentials = DEFAULT_WEIGHTS['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "my_list = [\"A\",\"B\",\"C\",\"D\"]\n",
    "\n",
    "for k in my_list:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of 0 is A.\n",
      "The value of 1 is B.\n",
      "The value of 2 is C.\n",
      "The value of 3 is D.\n"
     ]
    }
   ],
   "source": [
    "for idx, k in enumerate(my_list):\n",
    "    print(f\"The value of {idx} is {k}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Question\n",
    "\n",
    "How often would a vote that incorporates credibility-weighting by NFTs produce a different outcome than simply doing one wallet, one vote? We use the actual TE Academy NFT data as of May 28 to look at this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputting Sample Data \n",
    "\n",
    "In the cells below, we load the data available from the `.csv` file in the `VOTER_DATA_FILENAME`. \n",
    "\n",
    "If you wish to use a different `.csv` file, change this line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTER_DATA_FILENAME = \"../data/nft_data_may_28_2024_cleaned.csv\" # Adjust data here. \n",
    "\n",
    "voter_data = pd.read_csv(VOTER_DATA_FILENAME) #Convert to a Pandas DataFrame. \n",
    "\n",
    "# Sometimes there is a \n",
    "if ['Unnamed: 0'] in voter_data.columns:\n",
    "    voter_data.drop(columns = ['Unnamed: 0'], \n",
    "                    inplace = True)\n",
    "voter_data.set_index('ID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_voters = voter_data.to_dict(orient='index')\n",
    "sample_voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This next step isn't strictly necessary at this stage. \n",
    "voters = {key: UserNFTs(sample_voters.get(key))\n",
    "          for key, _ in sample_voters.items()\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with data, it's often helpful to see a particular entry to see what it looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_voter = list(sample_voters.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Weights\n",
    "\n",
    "We need to create a dictionary of weights for the NFTS. \n",
    "The dictionary `NFT_weights` gives a weight of 1.0 to each NFT held by current TEA owners.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFT_weights = {key: 1.0 \n",
    "               for key\n",
    "               in first_voter.keys()\n",
    "               }\n",
    "NFT_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Choice Weighted Plurality requires that voters have some kind of weight. \n",
    "The function below takes a dictionary of voters with NFTs held, and a dictionary of weights.\n",
    "It returns the weight that each voter should hold, based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_voter_weights_from_NFT_weight(voters: Dict,\n",
    "                                       nft_weights: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Given a list of voters, the NFTs they hold, and the \n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for voter in voters.keys():\n",
    "        new_dict[voter] = {}\n",
    "        new_dict[voter][\"weight\"] = 0\n",
    "        for nft_name, nft_val in nft_weights.items():\n",
    "            if voters.get(voter).get(nft_name):\n",
    "                new_dict[voter][\"weight\"] += nft_val\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the function to assign each voter a weight, based on the NFTs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_weights = calc_voter_weights_from_NFT_weight(voters,\n",
    "                                                   NFT_weights)\n",
    "voter_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison, we also create a version where each voter is assigned the same weight of 1.0, regardless of how many NFTs they hold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_weights = {voter: {}\"weight\": 1.0} for voter in sample_voters.keys()}\n",
    "uniform_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "The data generation is below. Each voter is randomly assigned a choice to vote for. \n",
    "The results of using SingleChoiceWeightedPlurality are calculated for each trial, based on these voter choices and weights. \n",
    "These results are stored in a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mechanism\n",
    "SCWPCalculator = SingleChoiceWeightedPlurality()\n",
    "\n",
    "# Set the number of experiments\n",
    "NUM_EXPERIMENTS = 10_000\n",
    "\n",
    "# Create an empty DataFrame to store simulation results\n",
    "results_list = [] \n",
    "\n",
    "for k in range(NUM_EXPERIMENTS):\n",
    "    # Generate choices for each voter\n",
    "    sample_choices = {\n",
    "                   key: choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                   for key in sample_voters.keys()\n",
    "                 }\n",
    "    \n",
    "    # Calculate who would win with weight of 1 per each NFT\n",
    "    weighted_winner, weighted_results  = SCWPCalculator.calculate(voter_weights,\n",
    "                            sample_choices)\n",
    "    # Calculate who would win with uniform weight \n",
    "    uniform_winner, uniform_results = SCWPCalculator.calculate(uniform_weights,\n",
    "                            sample_choices)\n",
    "                   \n",
    "    # Create an empty DataFrame to store simulation results\n",
    "    results_list.append({'Experiment': k,\n",
    "                        'weighted_winner': weighted_winner, \n",
    "                        'weighted_candidate_scores': weighted_results,\n",
    "                        'uniform_winner': uniform_winner,\n",
    "                        'uniform_candidate_scores': uniform_results,\n",
    "                        \"votes\": sample_choices\n",
    "                        }\n",
    "                        )\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "#TODO: Refactor for speed if needed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements\n",
    "\n",
    "We calculate what proportion of the time the two methods gave the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportion where they agreed. \n",
    "\n",
    "(results_df['weighted_winner'] == results_df['uniform_winner']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "# Define data\n",
    "categories = ['Giuseppe Destefanie', 'Vasily Sumanov', 'Roderick McKinley']\n",
    "values = [50, 30, 40]\n",
    "\n",
    "# Number of variables\n",
    "N = len(categories)\n",
    "\n",
    "# Compute angle of each axis\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Append the first value to the end to close the loop\n",
    "values += values[:1]\n",
    "\n",
    "# Initialize radar chart\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], categories)\n",
    "\n",
    "# Draw y-labels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([10, 20, 30, 40, 50], [\"10%\", \"20%\", \"30%\", \"40%\", \"50%\"], color=\"grey\", size=7)\n",
    "plt.ylim(0, 50)\n",
    "\n",
    "# Plot data\n",
    "ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
    "\n",
    "# Fill area\n",
    "ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of variables\n",
    "N = len(categories)\n",
    "\n",
    "# Compute angle of each axis\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Append the first value to the end to close the loop\n",
    "values += values[:1]\n",
    "\n",
    "# Initialize radar chart\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Draw one axis per variable and add labels\n",
    "plt.xticks(angles[:-1], categories)\n",
    "\n",
    "# Draw y-labels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([10, 20, 30, 40, 50], [\"10%\", \"20%\", \"30%\", \"40%\", \"50%\"], color=\"grey\", size=7)\n",
    "plt.ylim(0, 50)\n",
    "\n",
    "# Plot data\n",
    "ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
    "\n",
    "# Fill area\n",
    "ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    dict(\n",
    "        categories = ['Giuseppe Destefanie', 'Vasily Sumanov', 'Roderick McKinley', 'Candidate Four'],\n",
    "        values = [50, 30, 40, 20])\n",
    "        )\n",
    "fig = px.line_polar(df, r='values', theta='categories', line_close=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Here is an example code snippet in Python using [pandas](file:///c%3A/Users/andre/Desktop/basic-voting-calc/notebooks/experiment_template.ipynb#37%2C8-37%2C8) to read a .csv file from a Google Sheet link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'YOUR_GOOGLE_SHEET_LINK' with the link to your published Google Sheet .csv file\n",
    "google_sheet_link = 'https://docs.google.com/spreadsheets/d/1WJAV5O4otoTSH-E6wqJ8_GX4FdFO18GYB-F3b7IkKjA/edit?usp=sharing'\n",
    "\n",
    "# Read the .csv file from the Google Sheet link\n",
    "df = pd.read_csv(google_sheet_link)\n",
    "\n",
    "# Now you can work with the data in the DataFrame 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
